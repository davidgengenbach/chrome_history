{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyize Google Chrome history\n",
    "\n",
    "Code taken and minimally adapted from the [Analyzing Browser History Using Python and Pandas](https://applecrazy.github.io/blog/posts/analyzing-browser-hist-using-python/) blogpost by __AppleCrazy__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_FILE = 'data/history.txt'\n",
    "\n",
    "assert os.path.exists(HISTORY_FILE), 'History file \"{}\" does not exist! Please run get_chrome_history.sh'.format(HISTORY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_from_file_as_df(history_file):\n",
    "    # Open our file\n",
    "    with open(history_file) as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    # Strip whitespace then split on first occurrence of pipe character\n",
    "    raw_data = [line.strip().split('|', 1) for line in content]\n",
    "\n",
    "    data = pd.DataFrame(raw_data, columns=['datetime', 'url']).sort_values('datetime')\n",
    "    \n",
    "    # Had an error with this date? Must be an bug when exporting the history since there were no computers in 1601 (I guess?)\n",
    "    data = data[data.datetime != '1601-01-01 00:00:00']\n",
    "    parser = lambda u: urlparse(u).netloc\n",
    "    data['domain'] = data.url.apply(parser)\n",
    "\n",
    "    data.datetime = pd.to_datetime(data.datetime)\n",
    "    return data\n",
    "\n",
    "def get_domain_visit_counts(data):\n",
    "        # Aggregate domain entries\n",
    "    site_frequencies = data.domain.value_counts().to_frame()\n",
    "    # Make the domain a column\n",
    "    site_frequencies.reset_index(level=0, inplace=True)\n",
    "    # Rename columns to appropriate names\n",
    "    site_frequencies.columns = ['domain', 'count']\n",
    "    return site_frequencies\n",
    "\n",
    "def plot_domain_visit_counts_as_piechart(site_frequencies, with_labels = True, topN = 20, figsize = (10, 10)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title('Top {} Sites Visited'.format(topN))\n",
    "    pie_data = site_frequencies['count'].head(topN).tolist()\n",
    "    pie_labels = None\n",
    "    # Uncomment to get specific domain names\n",
    "    \n",
    "    if with_labels:\n",
    "        pie_labels = site_frequencies.apply(lambda x: '{} ({})'.format(x.domain, x[]), axis = 1).head(topN)\n",
    "    else:\n",
    "        pie_labels = None\n",
    "    \n",
    "    ax.pie(pie_data, autopct='%1.1f%%', labels=pie_labels)\n",
    "    return fig, ax\n",
    "\n",
    "data = get_history_from_file_as_df(HISTORY_FILE)\n",
    "site_frequencies = get_domain_visit_counts(data)\n",
    "fig, ax = plot_domain_visit_counts_as_piechart(site_frequencies)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
